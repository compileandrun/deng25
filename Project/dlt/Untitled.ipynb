{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install 'dlt[duckdb]'\n",
    "#!pip install 'dlt[bigquery]'\n",
    "#!pip install streamlit\n",
    "#!pip install \"dlt[gs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f48ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import duckdb\n",
    "\n",
    "import pyarrow\n",
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import OffsetPaginator, BasePaginator\n",
    "\n",
    "from dlt.destinations import filesystem #for GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cb6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "from dlt.sources.helpers.rest_client.paginators import BasePaginator\n",
    "from dlt.sources.helpers.requests import Response, Request\n",
    "\n",
    "class QueryParamPaginator(BasePaginator):\n",
    "    def __init__(self, page_param: str = \"page\", initial_page: int = 1):\n",
    "        super().__init__()\n",
    "        self.page_param = page_param\n",
    "        self.page = initial_page\n",
    "\n",
    "    def init_request(self, request: Request) -> None:\n",
    "        # This will set the initial page number (e.g., page=1)\n",
    "        self.update_request(request)\n",
    "\n",
    "    def update_state(self, response: Response, data: Optional[List[Any]] = None) -> None:\n",
    "        # Assuming the API returns an empty list when no more data is available\n",
    "        if not response.json():\n",
    "            self._has_next_page = False\n",
    "        else:\n",
    "            self.page += 1\n",
    "\n",
    "    def update_request(self, request: Request) -> None:\n",
    "        if request.params is None:\n",
    "            request.params = {}\n",
    "        request.params[self.page_param] = self.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ad01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "from dlt.sources.helpers.rest_client.paginators import BasePaginator\n",
    "from dlt.sources.helpers.requests import Response, Request\n",
    "\n",
    "#source for custom paginator: https://dlthub.com/docs/general-usage/http/rest-client#paginators\n",
    "#Chatgpt helped me build it based on that page.\n",
    "class TimeRangePaginator(BasePaginator):\n",
    "    def __init__(self, start_time: int, end_time: int, interval_ms: int):\n",
    "        super().__init__()\n",
    "        self.current_time = start_time\n",
    "        self.end_time = end_time\n",
    "        self.interval_ms = interval_ms\n",
    "\n",
    "    def init_request(self, request: Request) -> None:\n",
    "        \"\"\"Initialize the request with the first startTime and endTime\"\"\"\n",
    "        self.update_request(request)\n",
    "\n",
    "    def update_state(self, response: Response, data: Optional[List[Any]] = None) -> None:\n",
    "        \"\"\"Update the pagination state based on response data\"\"\"\n",
    "        if not response.json():  # Stop if no more data\n",
    "            self._has_next_page = False\n",
    "        else:\n",
    "            self.current_time += self.interval_ms\n",
    "\n",
    "    def update_request(self, request: Request) -> None:\n",
    "        \"\"\"Update the request parameters with the current time range\"\"\"\n",
    "        if request.params is None:\n",
    "            request.params = {}\n",
    "\n",
    "        next_end_time = min(self.current_time + self.interval_ms, self.end_time)\n",
    "        request.params['startTime'] = self.current_time\n",
    "        request.params['endTime'] = next_end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4591ed05",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggtrades.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with open('aggtrades.txt','r') as data:\n",
    "    data = data.read()\n",
    "data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e29b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbfbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0]['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c317aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(data[0]['T']/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ac647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c858ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('depth.txt','r') as depth:\n",
    "    depth = depth.read()\n",
    "depth = json.loads(depth)\n",
    "len(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef44f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7599df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    with open(file,'r') as file_name:\n",
    "        data = file_name.read()\n",
    "    data = json.loads(data)\n",
    "    print(len(data))\n",
    "    print(data[0])\n",
    "    #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604802d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file('trades.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file('depth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70959dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file('aggtrades.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe09407",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall pyarrow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768778bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pyarrow dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effde825",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec544df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eda2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744613681000\n",
      "1744614161000\n"
     ]
    }
   ],
   "source": [
    "start_time = int(datetime.utcnow().timestamp())*1000-60*1000*10\n",
    "print(start_time)\n",
    "end_time = int(datetime.utcnow().timestamp())*1000-60*1000*2\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e2afae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1744614161000'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "021130a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.resource(name=\"aggtrades\", write_disposition=\"append\") #aggtrades will be the table name\n",
    "def binance_api(start_timem,end_time):\n",
    "    client = RESTClient(\n",
    "        base_url=\"https://data-api.binance.vision\"\n",
    "        ,paginator=TimeRangePaginator(\n",
    "        #start_time=1672531200000,  # Start time in milliseconds (e.g., 2023-01-01)\n",
    "        #end_time=1672617600000,    # End time in milliseconds (e.g., 2023-01-02)\n",
    "        start_time=start_time,  # Start time in milliseconds (e.g., 2023-01-01)\n",
    "        end_time=end_time,    # End time in milliseconds (e.g., 2023-01-02)\n",
    "        interval_ms=60  * 1000  # 1-minute interval\n",
    "        )\n",
    "        \n",
    "    )\n",
    "\n",
    "    for page in client.paginate(\"/api/v3/aggTrades?symbol=BTCUSDT\"):\n",
    "        yield page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    destination=\"duckdb\", #database technology\n",
    "    pipeline_name='binance', #database name in the destination\n",
    "    dataset_name='aggtrade' #dataset name in the destination\n",
    ")\n",
    "\n",
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(binance_api, write_disposition=\"replace\")\n",
    "print(load_info)\n",
    "\n",
    "# explore loaded data\n",
    "pipeline.dataset(dataset_type=\"default\").aggtrades.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7add22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6482ca8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/koray/Documents/GitHub/deng25/Project/dlt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/koray/Documents/GitHub/deng25/Project/dlt')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "856850aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline binance load step completed in 2.25 seconds\n",
      "1 load package(s) were loaded to destination filesystem and into dataset aggtrade\n",
      "The filesystem destination used gs://elegant-bucket location to store data\n",
      "Load package 1744623951.227465 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    destination=\"filesystem\", #database technology\n",
    "    pipeline_name='binance', #database name in the destination\n",
    "    dataset_name='aggtrade' #dataset name in the destination\n",
    ")\n",
    "\n",
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(binance_api(start_time,end_time), write_disposition=\"append\", # appends create a new file each tim\n",
    "                         table_name='binance_data') #table name corresponds to a subfolder inside dataset_name\n",
    "print(load_info)\n",
    "\n",
    "# explore loaded data\n",
    "#pipeline.dataset(dataset_type=\"default\").aggtrades.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"data_things\",\n",
    "    destination=filesystem(\n",
    "        layout=\"{table_name}/{test_placeholder}/{timestamp}/{load_id}.{file_id}.{ext}\",\n",
    "        current_datetime=pendulum.now(),\n",
    "        extra_placeholders={\n",
    "            \"test_placeholder\": \"test_value\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt pipeline binance show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect('binance.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT * from INFORMATION_SCHEMA.tables').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT * from aggtrade.aggtrades').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ce388",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
