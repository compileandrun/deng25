{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install 'dlt[duckdb]'\n",
    "#!pip install 'dlt[bigquery]'\n",
    "#!pip install streamlit\n",
    "#!pip install \"dlt[gs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f48ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import duckdb\n",
    "\n",
    "import pyarrow\n",
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import OffsetPaginator, BasePaginator\n",
    "\n",
    "from dlt.destinations import filesystem #for GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cb6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "from dlt.sources.helpers.rest_client.paginators import BasePaginator\n",
    "from dlt.sources.helpers.requests import Response, Request\n",
    "\n",
    "class QueryParamPaginator(BasePaginator):\n",
    "    def __init__(self, page_param: str = \"page\", initial_page: int = 1):\n",
    "        super().__init__()\n",
    "        self.page_param = page_param\n",
    "        self.page = initial_page\n",
    "\n",
    "    def init_request(self, request: Request) -> None:\n",
    "        # This will set the initial page number (e.g., page=1)\n",
    "        self.update_request(request)\n",
    "\n",
    "    def update_state(self, response: Response, data: Optional[List[Any]] = None) -> None:\n",
    "        # Assuming the API returns an empty list when no more data is available\n",
    "        if not response.json():\n",
    "            self._has_next_page = False\n",
    "        else:\n",
    "            self.page += 1\n",
    "\n",
    "    def update_request(self, request: Request) -> None:\n",
    "        if request.params is None:\n",
    "            request.params = {}\n",
    "        request.params[self.page_param] = self.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ad01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "from dlt.sources.helpers.rest_client.paginators import BasePaginator\n",
    "from dlt.sources.helpers.requests import Response, Request\n",
    "\n",
    "#source for custom paginator: https://dlthub.com/docs/general-usage/http/rest-client#paginators\n",
    "#Chatgpt helped me build it based on that page.\n",
    "class TimeRangePaginator(BasePaginator):\n",
    "    def __init__(self, start_time: int, end_time: int, interval_ms: int):\n",
    "        super().__init__()\n",
    "        self.current_time = start_time\n",
    "        self.end_time = end_time\n",
    "        self.interval_ms = interval_ms\n",
    "\n",
    "    def init_request(self, request: Request) -> None:\n",
    "        \"\"\"Initialize the request with the first startTime and endTime\"\"\"\n",
    "        self.update_request(request)\n",
    "\n",
    "    def update_state(self, response: Response, data: Optional[List[Any]] = None) -> None:\n",
    "        \"\"\"Update the pagination state based on response data\"\"\"\n",
    "        if not response.json():  # Stop if no more data\n",
    "            self._has_next_page = False\n",
    "        else:\n",
    "            self.current_time += self.interval_ms\n",
    "\n",
    "    def update_request(self, request: Request) -> None:\n",
    "        \"\"\"Update the request parameters with the current time range\"\"\"\n",
    "        if request.params is None:\n",
    "            request.params = {}\n",
    "\n",
    "        next_end_time = min(self.current_time + self.interval_ms, self.end_time)\n",
    "        request.params['startTime'] = self.current_time\n",
    "        request.params['endTime'] = next_end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4591ed05",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggtrades.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with open('aggtrades.txt','r') as data:\n",
    "    data = data.read()\n",
    "data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e29b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbfbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0]['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c317aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(data[0]['T']/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ac647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c858ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('depth.txt','r') as depth:\n",
    "    depth = depth.read()\n",
    "depth = json.loads(depth)\n",
    "len(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef44f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7599df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    with open(file,'r') as file_name:\n",
    "        data = file_name.read()\n",
    "    data = json.loads(data)\n",
    "    print(len(data))\n",
    "    print(data[0])\n",
    "    #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604802d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file('trades.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file('depth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70959dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file('aggtrades.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe09407",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall pyarrow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768778bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pyarrow dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effde825",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec544df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021130a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.resource(name=\"aggtrades\", write_disposition=\"replace\") #aggtrades will be the table name\n",
    "def binance_api():\n",
    "    client = RESTClient(\n",
    "        base_url=\"https://data-api.binance.vision\"\n",
    "        ,paginator=TimeRangePaginator(\n",
    "        start_time=1672531200000,  # Start time in milliseconds (e.g., 2023-01-01)\n",
    "        end_time=1672617600000,    # End time in milliseconds (e.g., 2023-01-02)\n",
    "        interval_ms=60 * 60 * 1000  # 1-hour interval\n",
    "        )\n",
    "        \n",
    "    )\n",
    "\n",
    "    for page in client.paginate(\"/api/v3/aggTrades?symbol=BTCUSDT\"):\n",
    "        yield page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    destination=\"duckdb\", #database technology\n",
    "    pipeline_name='binance', #database name in the destination\n",
    "    dataset_name='aggtrade' #dataset name in the destination\n",
    ")\n",
    "\n",
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(binance_api, write_disposition=\"replace\")\n",
    "print(load_info)\n",
    "\n",
    "# explore loaded data\n",
    "pipeline.dataset(dataset_type=\"default\").aggtrades.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7add22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6482ca8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/koray/Documents/GitHub/deng25/Project/dlt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/koray/Documents/GitHub/deng25/Project/dlt')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "856850aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "PipelineStepFailed",
     "evalue": "Pipeline execution failed at stage sync with exception:\n\n<class 'dlt.common.configuration.exceptions.ConfigFieldMissingException'>\nFollowing fields are missing: ['bucket_url'] in configuration with spec FilesystemDestinationClientConfiguration\n\tfor field \"bucket_url\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key BINANCE__DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key BINANCE__DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BINANCE__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BUCKET_URL was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/Users/koray/Documents/GitHub/deng25/Project/dlt) is different from directory of your pipeline script (/Users/koray/opt/anaconda3/lib/python3.9/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials/ for more information\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigFieldMissingException\u001b[0m               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:784\u001b[0m, in \u001b[0;36mPipeline._sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    782\u001b[0m restored_schemas: Sequence[Schema] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m remote_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_state_from_destination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# if remote state is newer or same\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;66;03m# print(f'REMOTE STATE: {(remote_state or {}).get(\"_state_version\")} >= {state[\"_state_version\"]}')\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# TODO: check if remote_state[\"_state_version\"] is not in 10 recent version. then we know remote is newer.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:1537\u001b[0m, in \u001b[0;36mPipeline._restore_state_from_destination\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     schema \u001b[38;5;241m=\u001b[39m Schema(schema_name)\n\u001b[0;32m-> 1537\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_destination_clients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mas\u001b[39;00m job_client:\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job_client, WithStateSync):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:1265\u001b[0m, in \u001b[0;36mPipeline._get_destination_clients\u001b[0;34m(self, schema)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineConfigMissing(\n\u001b[1;32m   1258\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name,\n\u001b[1;32m   1259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdestination\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m directly or via .dlt config.toml file or environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1263\u001b[0m     )\n\u001b[0;32m-> 1265\u001b[0m destination_client, staging_client \u001b[38;5;241m=\u001b[39m \u001b[43mget_destination_clients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_destination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdestination_dataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstaging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_staging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in case of destination that does not need dataset name, we still must\u001b[39;49;00m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# provide one to staging\u001b[39;49;00m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO: allow for separate staging_dataset_name, that will require to migrate pipeline state\u001b[39;49;00m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#   to store it.\u001b[39;49;00m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstaging_dataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_dataset_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_staging\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_dataset_default_schema_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_schema_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_single_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(destination_client\u001b[38;5;241m.\u001b[39mconfig, DestinationClientStagingConfiguration):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/destinations/dataset/utils.py:86\u001b[0m, in \u001b[0;36mget_destination_clients\u001b[0;34m(schema, destination, destination_dataset_name, multi_dataset_default_schema_name, staging, staging_dataset_name)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# create instance with initial_config properly set\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mdestination\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client, staging_client\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/common/destination/reference.py:166\u001b[0m, in \u001b[0;36mDestination.client\u001b[0;34m(self, schema, initial_config)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a configured instance of the destination's job client\"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m caps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapabilities(config, schema\u001b[38;5;241m.\u001b[39mnaming)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/common/destination/reference.py:153\u001b[0m, in \u001b[0;36mDestination.configuration\u001b[0;34m(self, initial_config, accept_partial)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a fully resolved destination config from the initial config\"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_configuration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43msections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mknown_sections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDESTINATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestination_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Already populated values will supersede resolved env config\u001b[39;49;00m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_partial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_partial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/common/configuration/resolve.py:67\u001b[0m, in \u001b[0;36mresolve_configuration\u001b[0;34m(config, sections, explicit_value, accept_partial)\u001b[0m\n\u001b[1;32m     65\u001b[0m         log_traces(\u001b[38;5;28;01mNone\u001b[39;00m, config\u001b[38;5;241m.\u001b[39m__section__, \u001b[38;5;28mtype\u001b[39m(config), explicit_value, \u001b[38;5;28;01mNone\u001b[39;00m, traces)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resolve_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_partial\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/common/configuration/resolve.py:164\u001b[0m, in \u001b[0;36m_resolve_configuration\u001b[0;34m(config, explicit_sections, embedded_sections, explicit_value, accept_partial)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_resolved():\n\u001b[0;32m--> 164\u001b[0m     \u001b[43m_resolve_config_fields\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_partial\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# full configuration was resolved\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/common/configuration/resolve.py:304\u001b[0m, in \u001b[0;36m_resolve_config_fields\u001b[0;34m(config, explicit_values, explicit_sections, embedded_sections, accept_partial)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unresolved_fields:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConfigFieldMissingException(\u001b[38;5;28mtype\u001b[39m(config)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, unresolved_fields)\n",
      "\u001b[0;31mConfigFieldMissingException\u001b[0m: Following fields are missing: ['bucket_url'] in configuration with spec FilesystemDestinationClientConfiguration\n\tfor field \"bucket_url\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key BINANCE__DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key BINANCE__DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BINANCE__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BUCKET_URL was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/Users/koray/Documents/GitHub/deng25/Project/dlt) is different from directory of your pipeline script (/Users/koray/opt/anaconda3/lib/python3.9/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials/ for more information\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m dlt\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[1;32m      3\u001b[0m     destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#database technology\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m#database name in the destination\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggtrade\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#dataset name in the destination\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# run the pipeline with the new resource\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m load_info \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinance_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(load_info)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# explore loaded data\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:221\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    219\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:270\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    266\u001b[0m         ConfigSectionContext(\n\u001b[1;32m    267\u001b[0m             pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections, merge_style\u001b[38;5;241m=\u001b[39mmerge_func\n\u001b[1;32m    268\u001b[0m         )\n\u001b[1;32m    269\u001b[0m     ):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:712\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, table_format, schema_contract, refresh)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# sync state with destination\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrestore_from_destination\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev_mode\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_destination \u001b[38;5;129;01mor\u001b[39;00m destination)\n\u001b[1;32m    711\u001b[0m ):\n\u001b[0;32m--> 712\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sync_destination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstaging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# sync only once\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:175\u001b[0m, in \u001b[0;36mwith_schemas_sync.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mcommit_live_schema(name)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# because we committed live schema before calling f, we may safely\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# drop all changes in live schemas\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas\u001b[38;5;241m.\u001b[39mkeys()):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:853\u001b[0m, in \u001b[0;36mPipeline._sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_state(state)\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineStepFailed(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msync\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, ex, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at stage sync with exception:\n\n<class 'dlt.common.configuration.exceptions.ConfigFieldMissingException'>\nFollowing fields are missing: ['bucket_url'] in configuration with spec FilesystemDestinationClientConfiguration\n\tfor field \"bucket_url\" config providers and keys were tried in following order:\n\t\tIn Environment Variables key BINANCE__DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key BINANCE__DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BINANCE__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__FILESYSTEM__BUCKET_URL was not found.\n\t\tIn Environment Variables key DESTINATION__BUCKET_URL was not found.\n\t\tIn Environment Variables key BUCKET_URL was not found.\nWARNING: dlt looks for .dlt folder in your current working directory and your cwd (/Users/koray/Documents/GitHub/deng25/Project/dlt) is different from directory of your pipeline script (/Users/koray/opt/anaconda3/lib/python3.9/site-packages).\nIf you keep your secret files in the same folder as your pipeline script but run your script from some other folder, secrets/configs will not be found\nPlease refer to https://dlthub.com/docs/general-usage/credentials/ for more information\n"
     ]
    }
   ],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    destination=\"filesystem\", #database technology\n",
    "    pipeline_name='binance', #database name in the destination\n",
    "    dataset_name='aggtrade' #dataset name in the destination\n",
    ")\n",
    "\n",
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(binance_api, write_disposition=\"replace\")\n",
    "print(load_info)\n",
    "\n",
    "# explore loaded data\n",
    "pipeline.dataset(dataset_type=\"default\").aggtrades.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"data_things\",\n",
    "    destination=filesystem(\n",
    "        layout=\"{table_name}/{test_placeholder}/{timestamp}/{load_id}.{file_id}.{ext}\",\n",
    "        current_datetime=pendulum.now(),\n",
    "        extra_placeholders={\n",
    "            \"test_placeholder\": \"test_value\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt pipeline binance show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect('binance.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT * from INFORMATION_SCHEMA.tables').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT * from aggtrade.aggtrades').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ce388",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
